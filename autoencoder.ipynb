{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2434be5c",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "I want to use an autoencoder for dimensionality reduction on the full dataset with 1400+ features. <br>\n",
    "At the moment, the autoencoder has the following structure. <br>\n",
    "<br>\n",
    "\n",
    "![Diagram](AE_diagram.png)\n",
    "<br>\n",
    "The input variables are separated into categorical and continuous features. The categorical features are embedded and dropout is added. The continous features are treated with a batchnorm layer. Afterwards, all features are concatenate into a single Tensor. <br>\n",
    "The encoder is still very basic, consisting of two linear and one ReLu layer, reducing the dimensionality to 128 features. When using the full dataset with over 1400 features, I will probably add another linear layer (plus ReLu) going 512->256->128. <br>\n",
    "The decoder is the exact inverse of the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a89d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b9883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560c7cf",
   "metadata": {},
   "source": [
    "For now, I'll use the smaller, manually reduced, dataset to make testing faster. When everything is working well, I will run this on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6433b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0546217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].astype('float64')\n",
    "df['DAYS_ID_PUBLISH'] = df['DAYS_ID_PUBLISH'].astype('float64')\n",
    "df['SK_ID_CURR'] = df['SK_ID_CURR'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c36cc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_mean</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_min</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_max</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_mean</th>\n",
       "      <th>client_installments_AMT_PAYMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_max</th>\n",
       "      <th>client_installments_AMT_PAYMENT_mean_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53093.746</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>53093.746</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>219625.690</td>\n",
       "      <td>1008781.200</td>\n",
       "      <td>4.172888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175764.050</td>\n",
       "      <td>80773.380</td>\n",
       "      <td>560835.400</td>\n",
       "      <td>453952.220</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1150977.400</td>\n",
       "      <td>1618864.600</td>\n",
       "      <td>4394101.500</td>\n",
       "      <td>1.134881e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>31721.895</td>\n",
       "      <td>6.386539e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66116.266</td>\n",
       "      <td>25091.324</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>232499.700</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>1007153.400</td>\n",
       "      <td>1057860.200</td>\n",
       "      <td>3.719995e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12677.324</td>\n",
       "      <td>18330.390</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>172669.890</td>\n",
       "      <td>483756.38</td>\n",
       "      <td>825845.80</td>\n",
       "      <td>280199.700</td>\n",
       "      <td>806127.940</td>\n",
       "      <td>836703.400</td>\n",
       "      <td>1.139621e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0    100002.0     1.0         Cash loans           M    406597.5      24700.5   \n",
       "1    100003.0     0.0         Cash loans           F   1293502.5      35698.5   \n",
       "2    100004.0     0.0    Revolving loans           M    135000.0       6750.0   \n",
       "3    100006.0     0.0         Cash loans           F    312682.5      29686.5   \n",
       "4    100007.0     0.0         Cash loans           M    513000.0      21865.5   \n",
       "\n",
       "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0  Secondary / secondary special  Single / not married   \n",
       "1               Higher education               Married   \n",
       "2  Secondary / secondary special  Single / not married   \n",
       "3  Secondary / secondary special        Civil marriage   \n",
       "4  Secondary / secondary special  Single / not married   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
       "0                    0.018801     -9461.0  ...   \n",
       "1                    0.003541    -16765.0  ...   \n",
       "2                    0.010032    -19046.0  ...   \n",
       "3                    0.008019    -19005.0  ...   \n",
       "4                    0.028663    -19932.0  ...   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_mean  \\\n",
       "0                                    53093.746   \n",
       "1                                   175764.050   \n",
       "2                                    10573.965   \n",
       "3                                    66116.266   \n",
       "4                                    12677.324   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_min  \\\n",
       "0                               219625.700   \n",
       "1                                80773.380   \n",
       "2                                21288.465   \n",
       "3                                25091.324   \n",
       "4                                18330.390   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_max  \\\n",
       "0                                   53093.746   \n",
       "1                                  560835.400   \n",
       "2                                   10573.965   \n",
       "3                                  691786.900   \n",
       "4                                   22678.785   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_mean  \\\n",
       "0                                219625.700   \n",
       "1                                453952.220   \n",
       "2                                 21288.465   \n",
       "3                                232499.700   \n",
       "4                                172669.890   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_min_sum  \\\n",
       "0                                175783.73   \n",
       "1                               1154108.20   \n",
       "2                                 16071.75   \n",
       "3                                994476.70   \n",
       "4                                483756.38   \n",
       "\n",
       "  client_installments_AMT_INSTALMENT_min_sum  \\\n",
       "0                                  175783.73   \n",
       "1                                 1154108.20   \n",
       "2                                   16071.75   \n",
       "3                                  994476.70   \n",
       "4                                  825845.80   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_max  \\\n",
       "0                               219625.700   \n",
       "1                              1150977.400   \n",
       "2                                21288.465   \n",
       "3                               691786.900   \n",
       "4                               280199.700   \n",
       "\n",
       "  client_installments_AMT_PAYMENT_mean_sum  \\\n",
       "0                               219625.690   \n",
       "1                              1618864.600   \n",
       "2                                21288.465   \n",
       "3                              1007153.400   \n",
       "4                               806127.940   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_sum  \\\n",
       "0                                 1008781.200   \n",
       "1                                 4394101.500   \n",
       "2                                   31721.895   \n",
       "3                                 1057860.200   \n",
       "4                                  836703.400   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_sum  \n",
       "0                             4.172888e+06  \n",
       "1                             1.134881e+07  \n",
       "2                             6.386539e+04  \n",
       "3                             3.719995e+06  \n",
       "4                             1.139621e+07  \n",
       "\n",
       "[5 rows x 293 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631d7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype != 'float64':\n",
    "        df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e4314",
   "metadata": {},
   "source": [
    "To determine the size of categorical feature embeddings, I use a rule of thumb developed by the FastAI team. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbb20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_sz_rule(n_cat): return round(1.6 * n_cat**0.56) ## rule of thumb\n",
    "\n",
    "def def_emb_sz(df):\n",
    "    sz_dict = {}\n",
    "    n_cat = df.nunique().values\n",
    "    sz = [(x, emb_sz_rule(x)) for x in n_cat]\n",
    "\n",
    "    return sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a helper function that takes in the base dataset, does some preprocessing and returns the dataset split into train/test and categorical/continuous variables\n",
    "def load_data(df, valid_size=0.2):\n",
    "    x = df.drop(columns=['SK_ID_CURR', 'TARGET', 'test'])\n",
    "    x = x.replace([np.inf, -np.inf], np.nan) ## only needed for the reduced dataset, remove this when ready\n",
    "\n",
    "    ## train test split\n",
    "    ix = int(len(df)*valid_size)\n",
    "    x = x.sample(frac=1).reset_index() ## shuffle\n",
    "    x['valid'] = False\n",
    "    x.loc[0:ix, 'valid'] = True\n",
    "\n",
    "    \n",
    "    ## handle categorical variables\n",
    "    x_cat = x.select_dtypes(['category', 'bool'])\n",
    "    x_cat = x_cat.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    emb_sz = def_emb_sz(x_cat)[:-1] ## the last element is the \"valid\" variable, drop it\n",
    "    x_cat_train, x_cat_test = x_cat[x_cat['valid'] == False].drop(columns='valid'), x_cat[x_cat['valid'] == True].drop(columns='valid')\n",
    "    x_cat_train, x_cat_test = x_cat_train.values.reshape(-1, x_cat_train.shape[1]).astype('int64'), x_cat_test.values.reshape(-1, x_cat_test.shape[1]).astype('int64')\n",
    "    \n",
    "    ## handle continuous variables\n",
    "    x_cont = x.select_dtypes(['float64', 'bool'])\n",
    "    x_cont = x_cont.fillna(0)\n",
    "    x_cont_train, x_cont_test = x_cont[x_cont['valid'] == False].drop(columns='valid'), x_cont[x_cont['valid'] == True].drop(columns='valid')\n",
    "    x_cont_train, x_cont_test = x_cont_train.values.reshape(-1, x_cont_train.shape[1]).astype('float32'), x_cont_test.values.reshape(-1, x_cont_test.shape[1]).astype('float32')\n",
    "    \n",
    "    standardizer = preprocessing.StandardScaler()\n",
    "    x_cont_train = standardizer.fit_transform(x_cont_train) ## only fit on train set\n",
    "    x_cont_test = standardizer.transform(x_cont_test)\n",
    "    \n",
    "\n",
    "    return x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85c726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom dataset class\n",
    "class AEDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_cont, emb_sz):\n",
    "        self.x_cat, self.x_cont,self.emb_sz = x_cat, x_cont, emb_sz\n",
    "        self.n_cont = self.x_cont.shape[1]\n",
    "        self.n_cat = self.x_cat.shape[1]\n",
    "        self.len = self.x_cat.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x_cont[index], self.x_cat[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4587760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df):\n",
    "    x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz = load_data(df)\n",
    "    \n",
    "    train_dataset = AEDataset(x_cat_train, x_cont_train, emb_sz)\n",
    "    test_dataset = AEDataset(x_cat_test, x_cont_test, emb_sz)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ac0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_datasets(df)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=1024)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14439f5a",
   "metadata": {},
   "source": [
    "A very efficient way of adding noise to an input batch is Swap Noise. With a given probability p, a feature value is replaced with a random value of the same feature distribution. <br>\n",
    "The actual implementation is copied from [EtienneT's](https://github.com/EtienneT/TabularVAE/blob/master/TabularAE.ipynb) Variational Autoencoder for FastAI and adapted for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07590f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSwapNoise(torch.nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = torch.rand(x.size()) > (1 - self.p)\n",
    "            l1 = torch.floor(torch.rand(x.size()) * x.size(0)).type(torch.LongTensor)\n",
    "            l2 = (mask.type(torch.LongTensor) * x.size(1))\n",
    "            res = (l1 * l2).view(-1)\n",
    "            idx = torch.arange(x.nelement()) + res\n",
    "            idx[idx>=x.nelement()] = idx[idx>=x.nelement()]-x.nelement()\n",
    "            return x.flatten()[idx].view(x.size())\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a2c6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply BatchNorm, Dropout and Linear Layer\n",
    "class LinBnDrop(nn.Sequential):\n",
    "    def __init__(self, n_in, n_out, p):\n",
    "        layers = [nn.BatchNorm1d(n_in), nn.Dropout(p), nn.Linear(n_in, n_out)]\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "061d408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, dropout=0.2, noise=0.1):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in emb_szs])  \n",
    "        n_emb = sum([size for categories,size in emb_szs]) #sum embedding sizes\n",
    "        n_cat = sum([categories for categories,size in emb_szs]) ## sum category labels\n",
    "        self.n_emb, self.n_cont, self.n_cat = n_emb, n_cont, n_cat\n",
    "        self.n_input = n_emb + n_cont\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.emb_dropout = nn.Dropout(dropout)\n",
    "        self.bn_cont = nn.BatchNorm1d(self.n_cont)\n",
    "        self.noise = BatchSwapNoise(noise)\n",
    "     \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            LinBnDrop(n_in=self.n_input, n_out=256, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            LinBnDrop(n_in=256, n_out=128, p=self.dropout),\n",
    "        )\n",
    "          \n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            LinBnDrop(n_in=128, n_out=256, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            LinBnDrop(n_in=256, n_out=self.n_input, p=self.dropout),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    ## function to turn embeddings into label probabilities\n",
    "    def decode_embeddings(self, values, proba=False):\n",
    "\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "        start = 0\n",
    "\n",
    "        out = torch.empty((values.shape[0],0), requires_grad=True).long().to(device)\n",
    "\n",
    "        ### loop through each embedding\n",
    "        ## TODO: there has to be a better way to do this than a loop\n",
    "        for emb in self.embeddings:\n",
    "            \n",
    "            stop = start + emb.weight.data.shape[1]\n",
    "            \n",
    "            pred = torch.empty((0,emb.weight.data.shape[0])).to(device) ## create empty tensor of size (0,n) where n is the number of feature labels\n",
    "                \n",
    "            distance = ((emb.weight.data.unsqueeze(0) - values[:,start:stop].unsqueeze(1))**2).sum(axis=2) \n",
    "\n",
    "            p = softmax(-distance)\n",
    "                    \n",
    "            out = torch.cat([out,p],axis=1)\n",
    "            start = stop  \n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x_cont, x_cat, encode=False):\n",
    "\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "        \n",
    "        ## add batch swap noise\n",
    "        x_cat = self.noise(x_cat)\n",
    "        x_cont = self.noise(x_cont)\n",
    "\n",
    "        ## embedd categorical features and add dropout\n",
    "        x = [emb(x_cat[:,i]) for i, emb in enumerate(self.embeddings)]   \n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_dropout(x)\n",
    "\n",
    "        ## batch norm on continuous features\n",
    "        x2 = self.bn_cont(x_cont)\n",
    "        \n",
    "        ## concat cat and cont features\n",
    "        x = torch.cat([x, x2], 1) \n",
    "        \n",
    "        ## encode features\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        ## if I only want to encode features, stop here\n",
    "        if encode:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        ## decode encoded features\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        ## get continuous features\n",
    "        x_cont_out = x[:,self.n_emb:]\n",
    "        \n",
    "        ## get categorical features and reverse embedding\n",
    "        x_cat_out = x[:,0:self.n_emb]\n",
    "        x_cat_out = self.decode_embeddings(x_cat_out)\n",
    "        \n",
    "\n",
    "        return x_cont_out, x_cat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b166ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = train_dataset.len\n",
    "len_cont = train_dataset.n_cont\n",
    "emb_sz = train_dataset.emb_sz\n",
    "model = AutoEncoder(emb_sz, len_cont).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38f0b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    def forward(self, x_cont_ae, x_cat_ae, x_cont, x_cat):\n",
    "                    \n",
    "        ## loss for the continuous features is simply MSE\n",
    "        cont_loss = self.mse_loss(x_cont_ae, x_cont)\n",
    "        \n",
    "        ## the input categorical features are label encoded, but one-hot encoding is needed to calculate cross entropy loss\n",
    "        one_hot = torch.empty((x_cat.shape[0],0), requires_grad=True).long().to(device)\n",
    "        \n",
    "        for i in range(x_cat.shape[1]):\n",
    "            n_classes = train_dataset.x_cat[:,i].max() + 1 ## not every label is present in a batch, so I have to supply the amount of feature labels   \n",
    "            out = nn.functional.one_hot(x_cat[:,i], num_classes=n_classes).to(device)\n",
    "            one_hot = torch.cat([one_hot,out], axis=1)\n",
    "        \n",
    "        one_hot = one_hot.float()\n",
    "\n",
    "    \n",
    "        ## now I can easily calculate cross entropy loss\n",
    "        cat_loss = self.ce_loss(x_cat_ae, one_hot)\n",
    "        \n",
    "        ## take the sum as the final output\n",
    "        loss = cont_loss + cat_loss\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed8b2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = customLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35242603",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c5be1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 223.60. Valid loss: 153.00. Time: 5.23s\n",
      "Epoch 1. Train loss: 188.95. Valid loss: 138.80. Time: 5.14s\n",
      "Epoch 2. Train loss: 181.60. Valid loss: 130.54. Time: 5.46s\n",
      "Epoch 3. Train loss: 176.97. Valid loss: 125.56. Time: 5.21s\n",
      "Epoch 4. Train loss: 173.96. Valid loss: 122.50. Time: 5.25s\n",
      "Epoch 5. Train loss: 172.12. Valid loss: 120.24. Time: 5.28s\n",
      "Epoch 6. Train loss: 170.83. Valid loss: 118.82. Time: 5.14s\n",
      "Epoch 7. Train loss: 170.23. Valid loss: 118.15. Time: 5.16s\n",
      "Epoch 8. Train loss: 169.50. Valid loss: 117.04. Time: 5.36s\n",
      "Epoch 9. Train loss: 168.90. Valid loss: 116.67. Time: 5.61s\n",
      "Epoch 10. Train loss: 168.60. Valid loss: 116.17. Time: 5.34s\n",
      "Epoch 11. Train loss: 168.39. Valid loss: 115.79. Time: 5.30s\n",
      "Epoch 12. Train loss: 167.90. Valid loss: 115.52. Time: 5.40s\n",
      "Epoch 13. Train loss: 167.79. Valid loss: 115.18. Time: 5.48s\n",
      "Epoch 14. Train loss: 167.09. Valid loss: 114.95. Time: 5.51s\n",
      "Epoch 15. Train loss: 167.16. Valid loss: 114.79. Time: 5.23s\n",
      "Epoch 16. Train loss: 166.62. Valid loss: 114.40. Time: 5.11s\n",
      "Epoch 17. Train loss: 166.53. Valid loss: 114.55. Time: 5.27s\n",
      "Epoch 18. Train loss: 166.45. Valid loss: 113.88. Time: 5.47s\n",
      "Epoch 19. Train loss: 166.22. Valid loss: 113.65. Time: 5.13s\n",
      "Epoch 20. Train loss: 165.93. Valid loss: 113.66. Time: 5.11s\n",
      "Epoch 21. Train loss: 166.10. Valid loss: 113.64. Time: 5.26s\n",
      "Epoch 22. Train loss: 165.95. Valid loss: 113.47. Time: 5.19s\n",
      "Epoch 23. Train loss: 165.71. Valid loss: 113.04. Time: 5.38s\n",
      "Epoch 24. Train loss: 165.53. Valid loss: 112.96. Time: 5.09s\n",
      "Epoch 25. Train loss: 165.53. Valid loss: 113.07. Time: 5.21s\n",
      "Epoch 26. Train loss: 165.45. Valid loss: 113.05. Time: 5.24s\n",
      "Epoch 27. Train loss: 165.26. Valid loss: 112.76. Time: 5.33s\n",
      "Epoch 28. Train loss: 165.32. Valid loss: 112.90. Time: 5.35s\n",
      "Epoch 29. Train loss: 165.17. Valid loss: 112.52. Time: 5.22s\n",
      "Epoch 30. Train loss: 165.05. Valid loss: 112.72. Time: 5.17s\n",
      "Epoch 31. Train loss: 164.97. Valid loss: 112.66. Time: 5.36s\n",
      "Epoch 32. Train loss: 165.12. Valid loss: 112.47. Time: 5.42s\n",
      "Epoch 33. Train loss: 165.11. Valid loss: 112.44. Time: 5.56s\n",
      "Epoch 34. Train loss: 164.79. Valid loss: 112.29. Time: 5.36s\n",
      "Epoch 35. Train loss: 164.67. Valid loss: 112.15. Time: 5.44s\n",
      "Epoch 36. Train loss: 164.74. Valid loss: 112.28. Time: 5.23s\n",
      "Epoch 37. Train loss: 164.59. Valid loss: 112.09. Time: 5.22s\n",
      "Epoch 38. Train loss: 164.43. Valid loss: 112.26. Time: 5.36s\n",
      "Epoch 39. Train loss: 164.33. Valid loss: 111.96. Time: 5.27s\n",
      "Epoch 40. Train loss: 164.29. Valid loss: 112.05. Time: 5.31s\n",
      "Epoch 41. Train loss: 164.37. Valid loss: 112.16. Time: 5.30s\n",
      "Epoch 42. Train loss: 164.25. Valid loss: 112.07. Time: 5.44s\n",
      "Epoch 43. Train loss: 164.37. Valid loss: 111.41. Time: 5.48s\n",
      "Epoch 44. Train loss: 164.20. Valid loss: 111.77. Time: 5.49s\n",
      "Epoch 45. Train loss: 164.14. Valid loss: 111.83. Time: 5.44s\n",
      "Epoch 46. Train loss: 164.13. Valid loss: 111.51. Time: 5.55s\n",
      "Epoch 47. Train loss: 163.98. Valid loss: 111.60. Time: 5.32s\n",
      "Epoch 48. Train loss: 164.00. Valid loss: 111.76. Time: 5.28s\n",
      "No improvement for 5 epochs. Ending training.\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    tstart = time.time()\n",
    "    \n",
    "    ## train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        \n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "        \n",
    "        loss = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    ## validate\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        \n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "         \n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "        \n",
    "        loss = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_dataloader.dataset))\n",
    "    val_losses.append(valid_loss / len(test_dataloader.dataset))\n",
    " \n",
    "\n",
    "    tend = time.time()\n",
    "    print('Epoch {}. Train loss: {:.2f}. Valid loss: {:.2f}. Time: {:.2f}s'.format(e, train_losses[-1], val_losses[-1], tend-tstart))\n",
    "\n",
    "    if (e > patience) & (min(val_losses[-patience:]) != min(val_losses)):\n",
    "        print('No improvement for {} epochs. Ending training.'.format(patience))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a181f",
   "metadata": {},
   "source": [
    "## Preliminary Result\n",
    "The model converges pretty fast at a loss of around 164 during training and 111 during validation. A lower loss during validation looks concerning at first, but it should be expected since no regularization is applied during validation. <br>\n",
    "It is a very good sign that both curves are basically parallel. It looks like the model is able to find meaningful representations of the data. <br>\n",
    "I will try to improve performance a bit before moving on to the full dataset, as I expect significantly longer run times with 7x the feature count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f822a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame({'train': train_losses, 'valid': val_losses})\n",
    "ax = sns.lineplot(data=plot_df)\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f976b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
