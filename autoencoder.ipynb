{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3a89d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b9883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6433b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0546217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].astype('float64')\n",
    "df['DAYS_ID_PUBLISH'] = df['DAYS_ID_PUBLISH'].astype('float64')\n",
    "df['SK_ID_CURR'] = df['SK_ID_CURR'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c36cc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_mean</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_min</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_max</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_mean</th>\n",
       "      <th>client_installments_AMT_PAYMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_max</th>\n",
       "      <th>client_installments_AMT_PAYMENT_mean_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53093.746</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>53093.746</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>219625.690</td>\n",
       "      <td>1008781.200</td>\n",
       "      <td>4.172888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175764.050</td>\n",
       "      <td>80773.380</td>\n",
       "      <td>560835.400</td>\n",
       "      <td>453952.220</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1150977.400</td>\n",
       "      <td>1618864.600</td>\n",
       "      <td>4394101.500</td>\n",
       "      <td>1.134881e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>31721.895</td>\n",
       "      <td>6.386539e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66116.266</td>\n",
       "      <td>25091.324</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>232499.700</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>1007153.400</td>\n",
       "      <td>1057860.200</td>\n",
       "      <td>3.719995e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12677.324</td>\n",
       "      <td>18330.390</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>172669.890</td>\n",
       "      <td>483756.38</td>\n",
       "      <td>825845.80</td>\n",
       "      <td>280199.700</td>\n",
       "      <td>806127.940</td>\n",
       "      <td>836703.400</td>\n",
       "      <td>1.139621e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0    100002.0     1.0         Cash loans           M    406597.5      24700.5   \n",
       "1    100003.0     0.0         Cash loans           F   1293502.5      35698.5   \n",
       "2    100004.0     0.0    Revolving loans           M    135000.0       6750.0   \n",
       "3    100006.0     0.0         Cash loans           F    312682.5      29686.5   \n",
       "4    100007.0     0.0         Cash loans           M    513000.0      21865.5   \n",
       "\n",
       "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0  Secondary / secondary special  Single / not married   \n",
       "1               Higher education               Married   \n",
       "2  Secondary / secondary special  Single / not married   \n",
       "3  Secondary / secondary special        Civil marriage   \n",
       "4  Secondary / secondary special  Single / not married   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
       "0                    0.018801     -9461.0  ...   \n",
       "1                    0.003541    -16765.0  ...   \n",
       "2                    0.010032    -19046.0  ...   \n",
       "3                    0.008019    -19005.0  ...   \n",
       "4                    0.028663    -19932.0  ...   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_mean  \\\n",
       "0                                    53093.746   \n",
       "1                                   175764.050   \n",
       "2                                    10573.965   \n",
       "3                                    66116.266   \n",
       "4                                    12677.324   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_min  \\\n",
       "0                               219625.700   \n",
       "1                                80773.380   \n",
       "2                                21288.465   \n",
       "3                                25091.324   \n",
       "4                                18330.390   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_max  \\\n",
       "0                                   53093.746   \n",
       "1                                  560835.400   \n",
       "2                                   10573.965   \n",
       "3                                  691786.900   \n",
       "4                                   22678.785   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_mean  \\\n",
       "0                                219625.700   \n",
       "1                                453952.220   \n",
       "2                                 21288.465   \n",
       "3                                232499.700   \n",
       "4                                172669.890   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_min_sum  \\\n",
       "0                                175783.73   \n",
       "1                               1154108.20   \n",
       "2                                 16071.75   \n",
       "3                                994476.70   \n",
       "4                                483756.38   \n",
       "\n",
       "  client_installments_AMT_INSTALMENT_min_sum  \\\n",
       "0                                  175783.73   \n",
       "1                                 1154108.20   \n",
       "2                                   16071.75   \n",
       "3                                  994476.70   \n",
       "4                                  825845.80   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_max  \\\n",
       "0                               219625.700   \n",
       "1                              1150977.400   \n",
       "2                                21288.465   \n",
       "3                               691786.900   \n",
       "4                               280199.700   \n",
       "\n",
       "  client_installments_AMT_PAYMENT_mean_sum  \\\n",
       "0                               219625.690   \n",
       "1                              1618864.600   \n",
       "2                                21288.465   \n",
       "3                              1007153.400   \n",
       "4                               806127.940   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_sum  \\\n",
       "0                                 1008781.200   \n",
       "1                                 4394101.500   \n",
       "2                                   31721.895   \n",
       "3                                 1057860.200   \n",
       "4                                  836703.400   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_sum  \n",
       "0                             4.172888e+06  \n",
       "1                             1.134881e+07  \n",
       "2                             6.386539e+04  \n",
       "3                             3.719995e+06  \n",
       "4                             1.139621e+07  \n",
       "\n",
       "[5 rows x 293 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631d7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype != 'float64':\n",
    "        df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbb20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding size rule of thumb taken from FastAI\n",
    "def emb_sz_rule(n_cat): return round(1.6 * n_cat**0.56)\n",
    "\n",
    "def def_emb_sz(df):\n",
    "    sz_dict = {}\n",
    "    n_cat = df.nunique().values\n",
    "    sz = [(x, emb_sz_rule(x)) for x in n_cat]\n",
    "\n",
    "    return sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4de011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, valid_size=0.2):\n",
    "    x = df.drop(columns=['SK_ID_CURR', 'TARGET', 'test'])\n",
    "    x = x.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    ## train test split\n",
    "    ix = int(len(df)*valid_size)\n",
    "    x = x.sample(frac=1).reset_index() ## shuffle\n",
    "    x['valid'] = False\n",
    "    x.loc[0:ix, 'valid'] = True\n",
    "\n",
    "    x_cat = x.select_dtypes(['category', 'bool'])\n",
    "    x_cat = x_cat.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    emb_sz = def_emb_sz(x_cat)[:-1] ## the last element is the \"valid\" variable, drop it\n",
    "    x_cat_train, x_cat_test = x_cat[x_cat['valid'] == False].drop(columns='valid'), x_cat[x_cat['valid'] == True].drop(columns='valid')\n",
    "    x_cat_train, x_cat_test = x_cat_train.values.reshape(-1, x_cat_train.shape[1]).astype('int64'), x_cat_test.values.reshape(-1, x_cat_test.shape[1]).astype('int64')\n",
    "    \n",
    "\n",
    "    x_cont = x.select_dtypes(['float64', 'bool'])\n",
    "    x_cont = x_cont.fillna(0)\n",
    "    x_cont_train, x_cont_test = x_cont[x_cont['valid'] == False].drop(columns='valid'), x_cont[x_cont['valid'] == True].drop(columns='valid')\n",
    "    x_cont_train, x_cont_test = x_cont_train.values.reshape(-1, x_cont_train.shape[1]).astype('float32'), x_cont_test.values.reshape(-1, x_cont_test.shape[1]).astype('float32')\n",
    "    \n",
    "    \n",
    "    standardizer = preprocessing.StandardScaler()\n",
    "    x_cont_train = standardizer.fit_transform(x_cont_train)\n",
    "    x_cont_test = standardizer.transform(x_cont_test)\n",
    "    \n",
    "\n",
    "    return x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b85c726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_cont, emb_sz):\n",
    "        self.x_cat, self.x_cont,self.emb_sz = x_cat, x_cont, emb_sz\n",
    "        self.n_cont = self.x_cont.shape[1]\n",
    "        self.n_cat = self.x_cat.shape[1]\n",
    "        self.len = self.n_cont + self.n_cat\n",
    "\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x_cont[index], self.x_cat[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4587760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df):\n",
    "    x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz = load_data(df)\n",
    "    \n",
    "    train_dataset = AEDataset(x_cat_train, x_cont_train, emb_sz)\n",
    "    test_dataset = AEDataset(x_cat_test, x_cont_test, emb_sz)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47ac0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_datasets(df)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=1024)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "061d408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in emb_szs])  \n",
    "        n_emb = sum([size for categories,size in emb_szs]) #sum embedding sizes\n",
    "        n_cat = sum([categories for categories,size in emb_szs]) ## sum category labels\n",
    "        self.n_emb, self.n_cont, self.n_cat = n_emb, n_cont, n_cat\n",
    "        self.n_input = n_emb + n_cont\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.emb_dropout = nn.Dropout(dropout)\n",
    "        self.bn_cont = nn.BatchNorm1d(self.n_cont)\n",
    "\n",
    "         \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.n_input, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "        )\n",
    "          \n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, self.n_input),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def decode_embeddings(self, values, proba=False):\n",
    "        softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "        start = 0\n",
    "        \n",
    "        if proba:\n",
    "            out = torch.empty((290,0), requires_grad=True).long().to(device)\n",
    "        else:\n",
    "            out = torch.empty((290,14), requires_grad=True).long().to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### loop through each embedding\n",
    "        for emb in self.embeddings:\n",
    "            \n",
    "            stop = start + emb.weight.data.shape[1]\n",
    "            \n",
    "            pred = torch.empty((0,emb.weight.data.shape[0])).to(device) ## create empty tensor of size (0,n) where n is the number of feature labels\n",
    "                \n",
    "            ## loop through each item in the batch   \n",
    "            for i in range(290):\n",
    "                \n",
    "                ## get the euclidian distance between input values and feature embeddings\n",
    "                distance = ((emb.weight.data - values[i,start:stop])**2).sum(axis=1)\n",
    " \n",
    "                ## softmax assigns the highest probability to the highest input value\n",
    "                ## I take the negative to give assign the highest probability to the smallest distance\n",
    "                p = softmax(-distance).unsqueeze(0)\n",
    "                    \n",
    "                pred = torch.cat([pred,p])\n",
    "                    \n",
    "\n",
    "            out = torch.cat([out,pred],axis=1)\n",
    "            start = stop  \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x_cont, x_cat, encode=False):\n",
    "        \n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "\n",
    "        ## embedd categorical features and add dropout\n",
    "        x = [emb(x_cat[:,i]) for i, emb in enumerate(self.embeddings)]   \n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_dropout(x)\n",
    "\n",
    "        ## batch norm on continuous features\n",
    "        x2 = self.bn_cont(x_cont)\n",
    "        \n",
    "        ## concat cat and cont features\n",
    "        x = torch.cat([x, x2], 1) \n",
    "        \n",
    "        ## encode features\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        if encode:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        ## decode encoded features\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        ## get continuous features\n",
    "        x_cont_out = x[:,self.n_emb:]\n",
    "        \n",
    "        ## get categorical features and reverse embedding\n",
    "        x_cat_out = x[:,0:self.n_emb]\n",
    "        x_cat_out = self.decode_embeddings(x_cat_out, True)\n",
    "        \n",
    "        return x_cont_out, x_cat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5b166ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = train_dataset.len\n",
    "len_cont = train_dataset.n_cont\n",
    "emb_sz = train_dataset.emb_sz\n",
    "model = AutoEncoder(emb_sz, len_cont).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "38f0b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    def forward(self, x_cont_ae, x_cat_ae, x_cont, x_cat):\n",
    "\n",
    "        ## loss for the continuous features is simply MSE\n",
    "        cont_loss = self.mse_loss(x_cont_ae, x_cont)\n",
    "        \n",
    "        ## the input categorical features are label encoded, but one-hot encoding is needed to calculate cross entropy loss\n",
    "        one_hot = torch.empty((290,0), requires_grad=True).long().to(device)\n",
    "        \n",
    "        for i in range(x_cat.shape[1]):\n",
    "            n_classes = train_dataset.x_cat[:,i].max() + 1 ## not every label is present in a batch, so I have to supply the amount of feature labels   \n",
    "            out = nn.functional.one_hot(x_cat[:,i], num_classes=n_classes).to(device)\n",
    "            one_hot = torch.cat([one_hot,out], axis=1)\n",
    "        \n",
    "        one_hot = one_hot.float()\n",
    "     \n",
    "        ## now I can easily calculate cross entropy loss\n",
    "        cat_loss = self.ce_loss(x_cat_ae, one_hot)\n",
    "        \n",
    "        ## take the sum as the final output\n",
    "        loss = cont_loss + cat_loss\n",
    "        \n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed8b2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = customLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-2,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35242603",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5c5be1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 315.28. Valid loss: 331.46.\n",
      "Epoch 1. Train loss: 306.25. Valid loss: 316.58.\n",
      "Epoch 2. Train loss: 282.61. Valid loss: 294.51.\n",
      "Epoch 3. Train loss: 260.40. Valid loss: 274.12.\n",
      "Epoch 4. Train loss: 242.06. Valid loss: 280.88.\n",
      "Epoch 5. Train loss: 250.12. Valid loss: 290.34.\n",
      "Epoch 6. Train loss: 247.57. Valid loss: 277.35.\n",
      "Epoch 7. Train loss: 230.32. Valid loss: 272.22.\n",
      "Epoch 8. Train loss: 221.61. Valid loss: 263.60.\n",
      "Epoch 9. Train loss: 209.33. Valid loss: 255.52.\n",
      "Epoch 10. Train loss: 199.83. Valid loss: 246.45.\n",
      "Epoch 11. Train loss: 188.72. Valid loss: 241.13.\n",
      "Epoch 12. Train loss: 179.73. Valid loss: 238.89.\n",
      "Epoch 13. Train loss: 172.91. Valid loss: 236.48.\n",
      "Epoch 14. Train loss: 167.09. Valid loss: 233.55.\n",
      "Epoch 15. Train loss: 161.94. Valid loss: 230.08.\n",
      "Epoch 16. Train loss: 156.92. Valid loss: 227.37.\n",
      "Epoch 17. Train loss: 152.51. Valid loss: 226.11.\n",
      "Epoch 18. Train loss: 148.45. Valid loss: 225.32.\n",
      "Epoch 19. Train loss: 144.20. Valid loss: 224.10.\n",
      "Epoch 20. Train loss: 140.59. Valid loss: 221.98.\n",
      "Epoch 21. Train loss: 136.92. Valid loss: 220.65.\n",
      "Epoch 22. Train loss: 133.36. Valid loss: 219.78.\n",
      "Epoch 23. Train loss: 130.31. Valid loss: 218.66.\n",
      "Epoch 24. Train loss: 127.15. Valid loss: 217.88.\n",
      "Epoch 25. Train loss: 124.49. Valid loss: 217.27.\n",
      "Epoch 26. Train loss: 121.75. Valid loss: 215.93.\n",
      "Epoch 27. Train loss: 119.00. Valid loss: 214.78.\n",
      "Epoch 28. Train loss: 116.39. Valid loss: 214.23.\n",
      "Epoch 29. Train loss: 114.26. Valid loss: 213.77.\n",
      "Epoch 30. Train loss: 111.76. Valid loss: 213.34.\n",
      "Epoch 31. Train loss: 109.66. Valid loss: 213.27.\n",
      "Epoch 32. Train loss: 107.62. Valid loss: 212.25.\n",
      "Epoch 33. Train loss: 105.76. Valid loss: 211.89.\n",
      "Epoch 34. Train loss: 103.95. Valid loss: 212.25.\n",
      "Epoch 35. Train loss: 102.20. Valid loss: 210.93.\n",
      "Epoch 36. Train loss: 100.54. Valid loss: 211.26.\n",
      "Epoch 37. Train loss: 98.91. Valid loss: 211.01.\n",
      "Epoch 38. Train loss: 97.36. Valid loss: 210.43.\n",
      "Epoch 39. Train loss: 95.95. Valid loss: 210.43.\n",
      "Epoch 40. Train loss: 94.47. Valid loss: 210.31.\n",
      "Epoch 41. Train loss: 93.07. Valid loss: 210.04.\n",
      "Epoch 42. Train loss: 91.98. Valid loss: 210.07.\n",
      "Epoch 43. Train loss: 90.71. Valid loss: 209.88.\n",
      "Epoch 44. Train loss: 89.73. Valid loss: 209.98.\n",
      "Epoch 45. Train loss: 88.72. Valid loss: 210.34.\n",
      "Epoch 46. Train loss: 87.63. Valid loss: 209.99.\n",
      "Epoch 47. Train loss: 86.58. Valid loss: 209.75.\n",
      "Epoch 48. Train loss: 85.59. Valid loss: 210.19.\n",
      "Epoch 49. Train loss: 84.69. Valid loss: 210.10.\n",
      "Epoch 50. Train loss: 83.93. Valid loss: 210.46.\n",
      "Epoch 51. Train loss: 83.04. Valid loss: 210.83.\n",
      "Epoch 52. Train loss: 82.37. Valid loss: 210.68.\n",
      "Epoch 53. Train loss: 81.56. Valid loss: 210.63.\n",
      "Epoch 54. Train loss: 80.98. Valid loss: 211.14.\n",
      "Epoch 55. Train loss: 80.40. Valid loss: 210.83.\n",
      "Epoch 56. Train loss: 80.08. Valid loss: 212.14.\n",
      "Epoch 57. Train loss: 80.20. Valid loss: 211.10.\n",
      "No improvement for 10 epochs. Ending training.\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    \n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    train_losses.append(train_loss / len(train_dataloader.dataset))\n",
    "    val_losses.append(valid_loss / len(test_dataloader.dataset))\n",
    " \n",
    "    print('Epoch {}. Train loss: {:.2f}. Valid loss: {:.2f}.'.format(e, train_losses[-1], val_losses[-1]))\n",
    "    \n",
    "    if (e > patience) & (min(val_losses[-patience:]) != min(val_losses)):\n",
    "        print('No improvement for {} epochs. Ending training.'.format(patience))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "687db146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame({'train': train_losses, 'valid': val_losses})\n",
    "ax = sns.lineplot(data=plot_df)\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
