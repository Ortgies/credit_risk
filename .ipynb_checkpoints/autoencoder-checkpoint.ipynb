{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2434be5c",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "I want to use an autoencoder for dimensionality reduction on the full dataset with 1400+ features. <br>\n",
    "At the moment, the autoencoder has the following structure. <br>\n",
    "<br>\n",
    "\n",
    "![Diagram](AE_diagram.png)\n",
    "<br>\n",
    "The input variables are separated into categorical and continuous features. The categorical features are embedded and dropout is added. The continous features are treated with a batchnorm layer. Afterwards, all features are concatenate into a single Tensor. <br>\n",
    "The encoder is still very basic, consisting of two linear and one ReLu layer, reducing the dimensionality to 128 features. When using the full dataset with over 1400 features, I will probably add another linear layer (plus ReLu) going 512->256->128. <br>\n",
    "The decoder is the exact inverse of the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a89d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b9883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560c7cf",
   "metadata": {},
   "source": [
    "For now, I'll use the smaller, manually reduced, dataset to make testing faster. When everything is working well, I will run this on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6433b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7096615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "missing = pd.DataFrame(df.isnull().sum())\n",
    "missing['percent'] = 100 * missing / len(df)\n",
    "missing_columns = list(missing.index[missing['percent'] > 75])\n",
    "print(len(missing_columns))\n",
    "df = df.drop(columns=missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0546217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].astype('float64')\n",
    "df['DAYS_ID_PUBLISH'] = df['DAYS_ID_PUBLISH'].astype('float64')\n",
    "df['SK_ID_CURR'] = df['SK_ID_CURR'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c36cc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>client_installments_AMT_PAYMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_min_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_max</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_sum_max</th>\n",
       "      <th>client_installments_AMT_PAYMENT_mean_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_mean_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_max_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_max_sum</th>\n",
       "      <th>client_installments_AMT_PAYMENT_sum_sum</th>\n",
       "      <th>client_installments_AMT_INSTALMENT_sum_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>175783.73</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>219625.700</td>\n",
       "      <td>219625.690</td>\n",
       "      <td>219625.690</td>\n",
       "      <td>1008781.200</td>\n",
       "      <td>1008781.200</td>\n",
       "      <td>4.172888e+06</td>\n",
       "      <td>4.172888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1154108.20</td>\n",
       "      <td>1150977.400</td>\n",
       "      <td>1150977.400</td>\n",
       "      <td>1618864.600</td>\n",
       "      <td>1618864.600</td>\n",
       "      <td>4394101.500</td>\n",
       "      <td>4394101.500</td>\n",
       "      <td>1.134881e+07</td>\n",
       "      <td>1.134881e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>16071.75</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>31721.895</td>\n",
       "      <td>31721.895</td>\n",
       "      <td>6.386539e+04</td>\n",
       "      <td>6.386539e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>994476.70</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>691786.900</td>\n",
       "      <td>1007153.400</td>\n",
       "      <td>1007153.400</td>\n",
       "      <td>1057860.200</td>\n",
       "      <td>1057860.200</td>\n",
       "      <td>3.719995e+06</td>\n",
       "      <td>3.719995e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>483756.38</td>\n",
       "      <td>825845.80</td>\n",
       "      <td>280199.700</td>\n",
       "      <td>294631.120</td>\n",
       "      <td>806127.940</td>\n",
       "      <td>835985.300</td>\n",
       "      <td>836703.400</td>\n",
       "      <td>836703.400</td>\n",
       "      <td>1.139621e+07</td>\n",
       "      <td>1.179154e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0    100002.0     1.0         Cash loans           M            N   \n",
       "1    100003.0     0.0         Cash loans           F            N   \n",
       "2    100004.0     0.0    Revolving loans           M            Y   \n",
       "3    100006.0     0.0         Cash loans           F            N   \n",
       "4    100007.0     0.0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  client_installments_AMT_PAYMENT_min_sum  \\\n",
       "0  ...                                175783.73   \n",
       "1  ...                               1154108.20   \n",
       "2  ...                                 16071.75   \n",
       "3  ...                                994476.70   \n",
       "4  ...                                483756.38   \n",
       "\n",
       "  client_installments_AMT_INSTALMENT_min_sum  \\\n",
       "0                                  175783.73   \n",
       "1                                 1154108.20   \n",
       "2                                   16071.75   \n",
       "3                                  994476.70   \n",
       "4                                  825845.80   \n",
       "\n",
       "  client_installments_AMT_PAYMENT_sum_max  \\\n",
       "0                              219625.700   \n",
       "1                             1150977.400   \n",
       "2                               21288.465   \n",
       "3                              691786.900   \n",
       "4                              280199.700   \n",
       "\n",
       "  client_installments_AMT_INSTALMENT_sum_max  \\\n",
       "0                                 219625.700   \n",
       "1                                1150977.400   \n",
       "2                                  21288.465   \n",
       "3                                 691786.900   \n",
       "4                                 294631.120   \n",
       "\n",
       "  client_installments_AMT_PAYMENT_mean_sum  \\\n",
       "0                               219625.690   \n",
       "1                              1618864.600   \n",
       "2                                21288.465   \n",
       "3                              1007153.400   \n",
       "4                               806127.940   \n",
       "\n",
       "  client_installments_AMT_INSTALMENT_mean_sum  \\\n",
       "0                                  219625.690   \n",
       "1                                 1618864.600   \n",
       "2                                   21288.465   \n",
       "3                                 1007153.400   \n",
       "4                                  835985.300   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_max_sum  \\\n",
       "0                                 1008781.200   \n",
       "1                                 4394101.500   \n",
       "2                                   31721.895   \n",
       "3                                 1057860.200   \n",
       "4                                  836703.400   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_max_sum  \\\n",
       "0                              1008781.200   \n",
       "1                              4394101.500   \n",
       "2                                31721.895   \n",
       "3                              1057860.200   \n",
       "4                               836703.400   \n",
       "\n",
       "   client_installments_AMT_PAYMENT_sum_sum  \\\n",
       "0                             4.172888e+06   \n",
       "1                             1.134881e+07   \n",
       "2                             6.386539e+04   \n",
       "3                             3.719995e+06   \n",
       "4                             1.139621e+07   \n",
       "\n",
       "   client_installments_AMT_INSTALMENT_sum_sum  \n",
       "0                                4.172888e+06  \n",
       "1                                1.134881e+07  \n",
       "2                                6.386539e+04  \n",
       "3                                3.719995e+06  \n",
       "4                                1.179154e+07  \n",
       "\n",
       "[5 rows x 1401 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631d7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype != 'float64':\n",
    "        df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e4314",
   "metadata": {},
   "source": [
    "To determine the size of categorical feature embeddings, I use a rule of thumb developed by the FastAI team. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbb20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_sz_rule(n_cat): return round(1.6 * n_cat**0.56) ## rule of thumb\n",
    "\n",
    "def def_emb_sz(df):\n",
    "    sz_dict = {}\n",
    "    n_cat = df.nunique().values\n",
    "    sz = [(x, emb_sz_rule(x)) for x in n_cat]\n",
    "\n",
    "    return sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a helper function that takes in the base dataset, does some preprocessing and returns the dataset split into train/test and categorical/continuous variables\n",
    "def load_data(df, valid_size=0.2):\n",
    "    x = df.drop(columns=['SK_ID_CURR', 'TARGET', 'test'])\n",
    "    x = x.replace([np.inf, -np.inf], np.nan) ## only needed for the reduced dataset, remove this when ready\n",
    "\n",
    "    ## train test split\n",
    "    ix = int(len(df)*valid_size)\n",
    "    x = x.sample(frac=1).reset_index() ## shuffle\n",
    "    x['valid'] = False\n",
    "    x.loc[0:ix, 'valid'] = True\n",
    "\n",
    "    \n",
    "    ## handle categorical variables\n",
    "    x_cat = x.select_dtypes(['category', 'bool'])\n",
    "    x_cat = x_cat.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    emb_sz = def_emb_sz(x_cat)[:-1] ## the last element is the \"valid\" variable, drop it\n",
    "    x_cat_train, x_cat_test = x_cat[x_cat['valid'] == False].drop(columns='valid'), x_cat[x_cat['valid'] == True].drop(columns='valid')\n",
    "    x_cat_train, x_cat_test = x_cat_train.values.reshape(-1, x_cat_train.shape[1]).astype('int64'), x_cat_test.values.reshape(-1, x_cat_test.shape[1]).astype('int64')\n",
    "    \n",
    "    ## handle continuous variables\n",
    "    x_cont = x.select_dtypes(['float64', 'bool'])\n",
    "    x_cont = x_cont.fillna(0)\n",
    "    x_cont_train, x_cont_test = x_cont[x_cont['valid'] == False].drop(columns='valid'), x_cont[x_cont['valid'] == True].drop(columns='valid')\n",
    "    x_cont_train, x_cont_test = x_cont_train.values.reshape(-1, x_cont_train.shape[1]).astype('float32'), x_cont_test.values.reshape(-1, x_cont_test.shape[1]).astype('float32')\n",
    "    \n",
    "    standardizer = preprocessing.StandardScaler()\n",
    "    x_cont_train = standardizer.fit_transform(x_cont_train) ## only fit on train set\n",
    "    x_cont_test = standardizer.transform(x_cont_test)\n",
    "    \n",
    "\n",
    "    return x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b85c726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom dataset class\n",
    "class AEDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_cont, emb_sz):\n",
    "        self.x_cat, self.x_cont,self.emb_sz = x_cat, x_cont, emb_sz\n",
    "        self.n_cont = self.x_cont.shape[1]\n",
    "        self.n_cat = self.x_cat.shape[1]\n",
    "        self.len = self.x_cat.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x_cont[index], self.x_cat[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4587760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df):\n",
    "    x_cat_train, x_cat_test, x_cont_train, x_cont_test, emb_sz = load_data(df)\n",
    "    \n",
    "    train_dataset = AEDataset(x_cat_train, x_cont_train, emb_sz)\n",
    "    test_dataset = AEDataset(x_cat_test, x_cont_test, emb_sz)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ac0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_datasets(df)\n",
    "\n",
    "low = tensor(np.min(train_dataset.x_cont, axis=0)).to(device)\n",
    "high = tensor(np.max(train_dataset.x_cont, axis=0)).to(device)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=1024)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14439f5a",
   "metadata": {},
   "source": [
    "A very efficient way of adding noise to an input batch is Swap Noise. With a given probability p, a feature value is replaced with a random value of the same feature distribution. <br>\n",
    "The actual implementation is copied from [EtienneT's](https://github.com/EtienneT/TabularVAE/blob/master/TabularAE.ipynb) Variational Autoencoder for FastAI and adapted for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07590f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSwapNoise(torch.nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = torch.rand(x.size()) > (1 - self.p)\n",
    "            l1 = torch.floor(torch.rand(x.size()) * x.size(0)).type(torch.LongTensor)\n",
    "            l2 = (mask.type(torch.LongTensor) * x.size(1))\n",
    "            res = (l1 * l2).view(-1)\n",
    "            idx = torch.arange(x.nelement()) + res\n",
    "            idx[idx>=x.nelement()] = idx[idx>=x.nelement()]-x.nelement()\n",
    "            return x.flatten()[idx].view(x.size())\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633aa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply BatchNorm, Dropout and Linear Layer\n",
    "class LinBnDrop(nn.Sequential):\n",
    "    def __init__(self, n_in, n_out, p, bn=True):\n",
    "        if bn:\n",
    "            layers = [nn.BatchNorm1d(n_in), nn.Dropout(p), nn.Linear(n_in, n_out)]\n",
    "        else:\n",
    "            layers = [nn.Dropout(p), nn.Linear(n_in, n_out)]\n",
    "        \n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061d408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, low, high, dropout=0.2, emb_drop=0.01, noise=0.1):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in emb_szs])  \n",
    "        n_emb = sum([size for categories,size in emb_szs]) #sum embedding sizes\n",
    "        n_cat = sum([categories for categories,size in emb_szs]) ## sum category labels\n",
    "        self.n_emb, self.n_cont, self.n_cat = n_emb, n_cont, n_cat\n",
    "        self.n_input = n_emb + n_cont\n",
    "        self.dropout = dropout\n",
    "            \n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.emb_dropout = nn.Dropout(emb_drop)\n",
    "        self.bn_cont = nn.BatchNorm1d(self.n_cont)\n",
    "        self.noise = BatchSwapNoise(noise)\n",
    "     \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            LinBnDrop(n_in=self.n_input, n_out=1024, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            LinBnDrop(n_in=1024, n_out=512, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            LinBnDrop(n_in=512, n_out=256, p=self.dropout, bn=False)\n",
    "        )\n",
    "          \n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            LinBnDrop(n_in=256, n_out=512, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            LinBnDrop(n_in=512, n_out=1024, p=self.dropout),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_cont = nn.Sequential(\n",
    "            LinBnDrop(n_in=1024, n_out=self.n_cont, p=self.dropout, bn=False),\n",
    "            SigmoidRange(low=low, high=high)\n",
    "        )\n",
    "        \n",
    "        self.decoder_cat = nn.Sequential(\n",
    "            LinBnDrop(n_in=1024, n_out=self.n_cat, p=self.dropout, bn=False)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x_cont, x_cat, encode=False):\n",
    "\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "        \n",
    "        ## add batch swap noise\n",
    "        x_cat = self.noise(x_cat)\n",
    "        x_cont = self.noise(x_cont)\n",
    "\n",
    "        ## embedd categorical features and add dropout\n",
    "        x = [emb(x_cat[:,i]) for i, emb in enumerate(self.embeddings)]   \n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_dropout(x)\n",
    "  \n",
    "        ## concat cat and cont features\n",
    "        x = torch.cat([x, x_cont], 1) \n",
    "        \n",
    "        ## encode features\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        ## if I only want to encode features, stop here\n",
    "        if encode:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        ## decode encoded features\n",
    "        x = self.decoder(x)\n",
    "        x_cont_out = self.decoder_cont(x)\n",
    "        x_cat_out = self.decoder_cat(x)\n",
    "        \n",
    "\n",
    "        return x_cont_out, x_cat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b166ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = train_dataset.len\n",
    "len_cont = train_dataset.n_cont\n",
    "emb_sz = train_dataset.emb_sz\n",
    "model = AutoEncoder(emb_sz, len_cont, low, high).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "793f0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
    "        self.ce_loss = CrossEntropyLossFlat(reduction='sum')\n",
    "    \n",
    "    def forward(self, x_cont_ae, x_cat_ae, x_cont, x_cat):\n",
    "                    \n",
    "        ## loss for the continuous features is simply MSE\n",
    "        cont_loss = self.mse_loss(x_cont_ae, x_cont)\n",
    "        cont_loss = cont_loss / x_cont.shape[1]\n",
    "\n",
    "\n",
    "        cat_loss = x_cat_ae.new([0])\n",
    "        pos = 0\n",
    "        for i, (k,v) in enumerate(emb_sz): \n",
    "            cat_loss += self.ce_loss(x_cat_ae[:, pos:pos+k], x_cat[:,i])\n",
    "            pos += k\n",
    "        \n",
    "        cat_loss = cat_loss / x_cat.shape[1]\n",
    "        \n",
    "        ## take the sum as the final output\n",
    "        loss = cont_loss + cat_loss\n",
    "        \n",
    "        return loss, cont_loss, cat_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed8b2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = customLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35242603",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5be1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 51.40. Valid loss: 3.77. Time: 15.82s\n",
      "Epoch 1. Train loss: 3.54. Valid loss: 3.73. Time: 15.57s\n",
      "Epoch 2. Train loss: 2.92. Valid loss: 2.13. Time: 15.39s\n",
      "Epoch 3. Train loss: 1.64. Valid loss: 1.72. Time: 14.96s\n",
      "Epoch 4. Train loss: 1.39. Valid loss: 1.60. Time: 15.10s\n",
      "Epoch 5. Train loss: 1.28. Valid loss: 1.47. Time: 15.13s\n",
      "Epoch 6. Train loss: 1.19. Valid loss: 1.42. Time: 15.12s\n",
      "Epoch 7. Train loss: 1.15. Valid loss: 1.35. Time: 15.16s\n",
      "Epoch 8. Train loss: 1.11. Valid loss: 1.33. Time: 15.15s\n",
      "Epoch 9. Train loss: 1.08. Valid loss: 1.27. Time: 15.16s\n",
      "Epoch 10. Train loss: 1.04. Valid loss: 1.21. Time: 15.20s\n",
      "Epoch 11. Train loss: 1.01. Valid loss: 1.20. Time: 15.14s\n",
      "Epoch 12. Train loss: 0.98. Valid loss: 1.16. Time: 15.17s\n",
      "Epoch 13. Train loss: 0.96. Valid loss: 1.12. Time: 15.28s\n",
      "Epoch 14. Train loss: 0.93. Valid loss: 1.32. Time: 15.28s\n",
      "Epoch 15. Train loss: 0.91. Valid loss: 1.16. Time: 15.14s\n",
      "Epoch 16. Train loss: 0.90. Valid loss: 1.10. Time: 15.27s\n",
      "Epoch 17. Train loss: 0.88. Valid loss: 1.07. Time: 15.21s\n",
      "Epoch 18. Train loss: 0.86. Valid loss: 1.25. Time: 15.10s\n",
      "Epoch 19. Train loss: 0.85. Valid loss: 1.02. Time: 16.20s\n",
      "Epoch 20. Train loss: 0.84. Valid loss: 1.05. Time: 15.67s\n",
      "Epoch 21. Train loss: 0.82. Valid loss: 1.05. Time: 15.88s\n",
      "Epoch 22. Train loss: 0.81. Valid loss: 0.96. Time: 16.06s\n",
      "Epoch 23. Train loss: 0.80. Valid loss: 0.97. Time: 16.47s\n",
      "Epoch 24. Train loss: 0.79. Valid loss: 1.04. Time: 15.58s\n",
      "Epoch 25. Train loss: 0.78. Valid loss: 1.00. Time: 15.54s\n",
      "Epoch 26. Train loss: 0.79. Valid loss: 0.97. Time: 15.28s\n",
      "Epoch 27. Train loss: 0.78. Valid loss: 1.04. Time: 15.32s\n",
      "No improvement for 5 epochs. Ending training.\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    tstart = time.time()\n",
    "    \n",
    "    ## train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        \n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "        \n",
    "        loss,_,_ = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    ## validate\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        \n",
    "        x_cont, x_cat = data[0].to(device), data[1].to(device)\n",
    "         \n",
    "        x_cont_ae, x_cat_ae = model(x_cont, x_cat)\n",
    "         \n",
    "        loss,loss_cont,loss_cat = loss_function(x_cont_ae, x_cat_ae, x_cont, x_cat)\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_dataloader.dataset))\n",
    "    val_losses.append(valid_loss / len(test_dataloader.dataset))\n",
    "\n",
    "    tend = time.time()\n",
    "    print('Epoch {}. Train loss: {:.2f}. Valid loss: {:.2f}. Time: {:.2f}s'.format(e, train_losses[-1], val_losses[-1], tend-tstart))\n",
    "\n",
    "    if (valid_loss / len(test_dataloader.dataset)) == min(val_losses):\n",
    "        torch.save(model, 'autoencoder.pt') \n",
    "    \n",
    "    if (e > patience) & (min(val_losses[-patience:]) != min(val_losses)):\n",
    "        print('No improvement for {} epochs. Ending training.'.format(patience))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a181f",
   "metadata": {},
   "source": [
    "## Results\n",
    "The model performance looks very promising. Starting from a validation loss of 3.77 with randomized weights, the model is able to quickly reduce the loss to under 1.0 where it starts to converge. <br>\n",
    "Training and validation loss are very close, which is a good sign. The model seems to find meaningful representations of the input data. <br>\n",
    "There are probably still a lot of possibilities for improvement, from layer architecture to learning rate decay. But first I will use the model to compress the dataset and use the compressed features to predict credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f822a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame({'train': train_losses, 'valid': val_losses})\n",
    "ax = sns.lineplot(data=plot_df)\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.set_ylim([0, 5])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
